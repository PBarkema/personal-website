---
# Display name
title: Pieter Barkema

# Is this the primary user of the site?
superuser: true

# Role/position/tagline
role: PhD Candidate in Cognitive Neuroscience

# Organizations/Affiliations to show in About widget
organizations:
- name: University College London
  url: https://www.ucl.ac.uk/

# Short bio (displayed in user profile at end of posts)
bio: My research interests focuses on faulty Human and Machine Intelligence.

# Interests to show in About widget

interests:
  - Mechanistic Interpretability
  - Uncertainty Quantification
  - Science of Hallucinations
  - Computational Neuroscience

# Education to show in About widget
education:
  courses:
  - course: PhD in Cognitive Neuroscience
    institution: University College London
    year: 2026
  - course: MSc in Neuroscience
    institution: King's College London
    year: 2021
  - course: BSc in Artificial Intelligence
    institution: Utrecht University
    year: 2019

# Social/Academic Networking
# For available icons, see: https://wowchemy.com/docs/getting-started/page-builder/#icons
#   For an email link, use "fas" icon pack, "envelope" icon, and a link in the
#   form "mailto:your-email@example.com" or "/#contact" for contact widget.
social:
- icon: envelope
  icon_pack: fas
  link: 'mailto:pieter.barkema.22@ucl.ac.uk'
- icon: graduation-cap  # Alternatively, use `google-scholar` icon from `ai` icon pack
  icon_pack: fas
  link: https://scholar.google.com/citations?hl=en&user=fuyD_YcAAAAJ
- icon: github
  icon_pack: fab
  link: https://github.com/pbarkema
- icon: linkedin
  icon_pack: fab
  link: https://www.linkedin.com/in/pieter-barkema-nl/

# Link to a PDF of your resume/CV.
# To use: copy your resume to `static/uploads/resume.pdf`, enable `ai` icons in `params.toml`, 
# and uncomment the lines below.
# - icon: cv
#   icon_pack: ai
#   link: uploads/resume.pdf

# Enter email to display Gravatar (if Gravatar enabled in Config)
email: "pieter.barkema.22@ucl.ac.uk"

# Highlight the author in author lists? (true/false)
highlight_name: true
---

I am a **Brain & AI Scientist** at **University College London**, and a **Scientific Programmer** at Donders Institute. I am interested in how the Human Brain creates **Hallucinations** and learns **Uncertainty**, both huge problems in AI Safety. I want to leverage my unique perspective to help overcome these challenges. I currently lead two multi-year experimental brain scanning studies (7T fMRI and MEG) and one computational modelling study (**Deep Neural Networks**, **Bayesian Modelling**) to investigate how human neural networks create false beliefs (hallucination) and calculate uncertainty about its own internal states (introspection) - leading to multiple peer-reviewed articles and high-profile talks. I have professional experience evaluating and training LLMs at **Google Assistant**, and developed [PCNportal](https://pcnportal.dccn.nl/), a collaborative **open-source Machine Learning app** for big data brain analysis.

Humans and LLMs are both interrogable black boxes. I want to use my scientific expertise to make LLMs become more accurate in their thinking, through experimental design and computational modelling of their internal representations. 

{{< icon name="download" pack="fas" >}} Download my {{< staticref "uploads/Pieter_Barkema_CV_AISafety.pdf" "newtab" >}}resum√©{{< /staticref >}}.
